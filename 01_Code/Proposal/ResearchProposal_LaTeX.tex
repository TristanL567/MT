%==== KNITR ===================================================================%



%==== START ===================================================================%

\documentclass{report}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage[left=2cm, right=2cm, top=1cm, bottom=2cm]{geometry}

% Font.


% Main packages.
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs} 
\usepackage{rotating} 
\usepackage{lmodern}

% Citations.
\usepackage{natbib}
\setcitestyle{authoryear,open={(},close={)}} %Citation-related commands

% Required for Table.


%%

\title{Master Thesis - Research Proposal}
\author{Tristan Leiter}
\date{\today}

%==== DOCUMENT START ==========================================================%

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\maketitle

%==== ABSTRACT ================================================================%

\begin{abstract}
This report demonstrates the integration of R code and its output within a LaTeX document using Sweave. It covers the basic structure of a report, including a summary, chapters with subchapters, and a bibliography.
\end{abstract}

%==== Table of content ========================================================%

% \tableofcontents
% \newpage

%==== Chapter 1: Problem Description ==========================================%

\chapter{Problem Description}

\section{Introduction}

% The theoretical foundation of modern portfolio management relies on the diversification of idiosyncratic risk. Empirical evidence suggests that the distribution of individual stock returns is not normally distributed, but is instead characterized by extreme skewness and "fat tails". \\

Research by J.P. Morgan Asset Management highlights an empirical phenomenon referred to as "The Agony and the Ecstasy" \citep{Cembalest2014, Cembalest2024} revealing that equity indices, like the Russell 3000, are overwhelmingly influenced by extreme stock performances. While a small percentage of winners contribute the vast majority of excess returns, approximately 40\% of all constituents suffer a "catastrophic decline," which is defined as a drawdown of 70\% or more from their peak without a subsequent recovery. \\

Recent literature formalizes this phenomenon as a \textbf{"Catastrophic Stock Implosion"} (CSI) \citep{Tewari2024}. Unlike standard volatility, an implosion represents a distinct market event characterized by a severe price downturn followed by prolonged stagnation and minimal probability of recovery. This presents a critical challenge for index construction: passive investing captures the "Ecstasy" of winners but systematically forces investors to hold the "Agony" of these imploding assets (atleast until removal from the constituent index). Crucially, as explored by \citep{Cembalest2014, Cembalest2024}, these declines are not limited to speculative "junk" companies; a significant portion of losers display "healthy" fundamentals prior to collapse, suggesting traditional metrics fail to capture the dynamics preceding permanent capital decline.

\section{Status Quo}

Despite the extensive literature on corporate insolvency dating back to seminal works on discriminant analysis, the effective modeling of bankruptcy—and specifically the pre-emptive identification of catastrophic stock drawdowns—remains an elusive goal. This persistence of risk stems not from a lack of data, but from the structural limitations of the methods currently in use. The prevailing paradigm relies heavily on static accounting indicators and linear assumptions, which often fail to capture the dynamic, noisy, and non-normal reality of modern equity markets. Consequently, the task of filtering out "implosion" candidates is inherently difficult due to the following fundamental frictions:

\begin{enumerate}
    \item \textbf{The Quality Trap:}  Recent literature has explored indicators, which are perceived to be synonymous with healthy stock fundamentals. \citet{Penman2018} suggest that the Book-to-Price ratio (B/P) is misleading. Low B/P values reflect uncertainty about future cash-flows rather than
"cheap" buying opportunities. Additionally, \citet{Altman2016} argue that, amongst others, profitability is time-varying and find low predictive ability for longer time-periods. Specifically, while they find that profitability ratios like Return on Assets (ROA) provide efficient accuracy for a short horizon of two years , these measures fail to be consistent predictors over a ten-year horizon. They observe that in multivariate models, profitability is rendered largely insignificant when tested against solvency measures, such as the Equity Ratio, which dominates the prediction of distress irrespective of the horizon length.

  \item \textbf{Predictive Limitations of Linearity:} Traditional bankruptcy models heavily rely on linear combinations of ratios, which may be insufficient for capturing modern market dynamics. \cite{Jones2017} categorize techniques like Linear Discriminant Analysis (LDA) and standard logit/probit models as rigid structures that struggle with the "noisy" datasets typical in finance. In a comparative evaluation of 16 classifiers, \cite{Jones2017} find that these linear baselines are sharply outperformed by statistical learning techniques, particularly AdaBoost, Generalized Boosting, and Random Forests. While linear models deteriorate when facing multicollinearity or non-normal data distributions, these ensemble methods demonstrate superior accuracy on both cross-sectional and longitudinal test samples without requiring variable transformation. \\
  
\item \textbf{Misalignment of Prediction Horizons and Objectives:} 
While traditional bankruptcy models aim to minimize credit risk, they often fail to minimize market risk. A fundamental disconnect exists between \textit{legal insolvency} and \textit{market implosion}.

\begin{itemize}
    \item \textbf{Lagging Indicators:} Legal bankruptcy is frequently the final stage of a long deterioration process. By the time a traditional Altman Z-Score or structural model flags a company as distressed, the market has often already priced in the failure, resulting in a "Zombie state" where the asset lingers at depressed valuations \citep{Tewari2024}. For an equity investor, the capital is lost at the \textit{implosion} event, not the bankruptcy filing.
    \item \textbf{The Cost of False Positives (Type I Errors):} In the context of equity indexing, the cost of a False Positive is not merely administrative; it is an opportunity cost. As noted in the "Agony and Ecstasy" framework, index returns are driven by a small tail of extreme winners. Traditional models, which penalize negative skewness too aggressively, risk flagging volatile but successful growth stocks as "distressed." Excluding a future "Ecstasy" stock due to a conservative model would severely underperform the benchmark, negating the benefits of avoiding the "Agony" stocks.
\end{itemize}

\end{enumerate}

\section{Research Gap and Proposed Methodology}

\subsection{Implications of Current Limitations}

While the literature on bankruptcy prediction is extensive, there is a lack of research applying modern Machine Learning (ML) techniques to the specific problem of \textit{market-based} catastrophic declines in the cross-section of prior "healthy" index constituents with a focus on enhanced index construction. \\

Recent work has demonstrated that ML models, such as Gradient Boosting and Neural Networks, outperform traditional statistical models in predicting financial distress by capturing non-linear relationships between variables \citep{Jabeur2021, Jabeur2023}, \citep{Tewari2024}. For instance, ensemble models like CatBoost and XGBoost have shown superior classification accuracy in corporate failure prediction compared to discriminant analysis and logistic regression. \\

\begin{enumerate}
    \item \textbf{From Ratios to Raw Data:} By utilizing raw financial data rather than derivative ratios, Machine Learning (ML) algorithms can autonomously learn complex, non-linear dependencies and interaction effects that traditional ratios (like Book-to-Price) fail to capture.
    \item \textbf{From Static to Dynamic:} Financial distress is rarely a static state but a sequence of deteriorating signals. Traditional cross-sectional models ignore the temporal trajectory of firm fundamentals.
\end{enumerate}

\subsection{Proposed Approach: The "Crash-Filtered" Index}
This thesis proposes bridging the gap between distress prediction and active index construction. While \citet{Tewari2024} established the concept of Catastrophic Stock Implosion, it remains unknown whether these insights can be operationalized into a viable risk-mitigation strategy.

To address the "Agony and Ecstasy" dilemma, this research aims to move from "pure volatility forecasting" to "probabilistic implosion modeling." The proposed methodology improves upon the status quo in three specific ways:

\begin{enumerate}
    \item \textbf{Advanced Ensemble Modeling:} Utilizing Bagging and Boosting algorithms (e.g., XGBoost, CatBoost) to handle the non-linear feature interactions of raw market and fundamental data.
    \item \textbf{Temporal Dynamics with Deep Learning:} Extending the work of \cite{Jabeur2023} by incorporating Long Short-Term Memory (LSTM) networks. This allows the model to treat company health as a time-series problem, detecting the \textit{rate of change} in fundamentals that precedes a crash, potentially reducing the "lag" associated with traditional models.
    \item \textbf{Predictive Exclusion Framework:} Constructing a "Crash-Filtered" index using Rolling-Forward Cross-Validation. Instead of the traditional binary exclusion (listing failure), this framework applies a probabilistic threshold. The goal is to systematically exclude identified "implosion" candidates while retaining the "Ecstasy" winners, thereby isolating the Alpha generated purely by risk mitigation.
\end{enumerate}

%==== Chapter 2: Research Question ============================================%

\chapter{Research Question}

Based on the identified problem that standard metrics fail to distinguish between "recoverable volatility" and "permanent implosion" and that perceived quality-signals can be misleading, the following research question could be explored:

\section{Main Research Question}

\textit{Does a ML-risk filtered equity index, constructed by excluding stocks with a high implied probability of catastrophic implosion, generate statistically significant superior risk-adjusted returns compared to the market-weighted benchmark and traditional volatility-filtered indices?}

\subsection{Sub-Question 1: Predictive Superiority}

\textit{Can Machine Learning models (e.g., CatBoost, XGBoost or Neural Networks) calibrated to the definition of "Catastrophic Implosion" outperform traditional distress models (e.g., Altman Z-Score) in distinguishing between permanent capital loss and temporary drawdown?} \\

This addresses the "Zombie State" gap, testing if ML can identify stocks that implode but do not necessarily go bankrupt. It also leverages the finding that advanced algorithms like CatBoost, XGBoost and Neural Networks provide higher accuracy in distress prediction than traditional linear models.

\subsection{Sub-Question 2: Portfolio Distinction}

\textit{Does the "Implosion-Filtered" portfolio exhibit lower risk characteristics (measured by maximum drawdown and expected shortfall) than standard risk-controlling models (low volatility, low beta, ...)?} \\ 

This tests the hypothesis that avoiding \textit{implosions} (permanent loss) provides a distinct risk profile compared to avoiding \textit{volatility} (temporary noise), potentially allowing the investor to retain exposure to high-growth, high-volatility winners that do not implode.

%==== Chapter 3: Data =========================================================%








%==== Chapter 4: Expected Results =============================================%

% \chapter{Expected Results}
% We expect to validate the findings regarding distress risk discussed by \citet{Campbell2005}.


%==== Chapter 5: Methodology ==================================================%



%==== Chapter 6: Research Background ==========================================%



%==== Chapter 7: References ===================================================%

\bibliographystyle{plainnat} 
\bibliography{references}

%==== Appendix ================================================================%

% \appendix 
% 
% \chapter{Overview}

%==== END =====================================================================%

\end{document}
